# ğŸ“ˆ Brique 6 â€” ScalabilitÃ© & Infrastructure

**PrioritÃ© globale : ğŸŸ  HAUTE**  
**Score de prÃ©paration : 5/10**

---

## Architecture actuelle

```
Client (React SPA) â†’ Next.js App Router (Vercel Serverless) â†’ Supabase (PostgreSQL)
                                    â†“
                            Google Gemini AI (Oracle)
                            OpenAI (fallback Oracle)
```

### Points forts
- Vercel serverless = scaling auto des fonctions
- Supabase managed = PostgreSQL managÃ© + API REST
- Pas de state serveur (stateless) = scalable horizontalement
- Cache in-memory de la config algorithme via `globalThis`
- Assets statiques servis par CDN Vercel

### Points faibles
- Aucun cache intermÃ©diaire (Redis, KV store)
- Rate limiting en mÃ©moire (inefficace en serverless)
- Race conditions sur les opÃ©rations d'Ã©criture en DB
- Pas de queue/worker pour les opÃ©rations lourdes

---

## ğŸ”´ ProblÃ¨mes critiques

### 1. Rate limiting en mÃ©moire
- **Fichier :** `src/lib/rateLimit.ts`
- Utilise `new Map()` en mÃ©moire â†’ perdu Ã  chaque cold start, non partagÃ© entre instances
- **Si le jeu devient viral (10K+ utilisateurs simultanÃ©s) :** Le rate limiting est inexistant
- Routes de login admin exposÃ©es au brute force Ã  grande Ã©chelle
- **Solution :** Upstash Redis (`@upstash/ratelimit`) â€” coÃ»t : ~10â‚¬/mois pour 10K req/jour

### 2. Race conditions sur les votes ELO
- **Fichier :** `src/lib/repositories/votes.ts`
- Processus actuel : `SELECT elo` â†’ calcul en JS â†’ `UPDATE SET elo = nouvelle_valeur`
- Si 2 votes arrivent simultanÃ©ment sur le mÃªme Ã©lÃ©ment :
  - Vote A lit `elo = 1000`
  - Vote B lit `elo = 1000`
  - Vote A Ã©crit `elo = 1016`
  - Vote B Ã©crit `elo = 1008` â† **Ã©crase le rÃ©sultat de A**
- 8 opÃ©rations parallÃ¨les dans `processVote()` aggravent le risque
- **Solution :** Utiliser `UPDATE elements SET elo = elo + delta` (atomique en PostgreSQL) ou une RPC Supabase

### 3. Race conditions sur les feedbacks
- **Fichier :** `src/lib/repositories/feedback.ts`
- MÃªme pattern select-then-update â†’ les thumbs/stars peuvent Ãªtre perdus
- **Solution :** `UPDATE SET nb_thumbs_up = nb_thumbs_up + 1`

---

## ğŸŸ  ProblÃ¨mes haute prioritÃ©

### 4. `getAllElementsEnriched` charge toutes les votes
- **Fichier :** `src/lib/repositories/elements.ts`
- Pour compter les participations, la fonction fetch **TOUTES les votes** de la table puis compte en JS
- Avec 10K votes â†’ ~100Ko de donnÃ©es transfÃ©rÃ©es Ã  chaque appel
- Avec 1M votes â†’ ce sera inutilisable
- **Solution :** CrÃ©er une vue SQL ou une RPC qui fait le `COUNT GROUP BY` cÃ´tÃ© Supabase

### 5. Leaderboard sans pagination
- **Fichier :** `src/app/api/leaderboard/route.ts`
- Retourne TOUS les Ã©lÃ©ments actifs en une requÃªte
- Actuellement ~94 Ã©lÃ©ments â†’ OK
- Avec 500+ Ã©lÃ©ments â†’ rÃ©ponse lente, gros JSON, mÃ©moire client
- **Solution :** Pagination avec `limit/offset` + infinite scroll cÃ´tÃ© client

### 6. Pas de caching des rÃ©ponses API
- Toutes les routes API utilisent `force-dynamic` (Next.js `export const dynamic = 'force-dynamic'`)
- Le leaderboard est recalculÃ© Ã  chaque requÃªte
- Les stats publiques aussi
- **Solution :** 
  - Leaderboard : `Cache-Control: s-maxage=60, stale-while-revalidate=300`
  - Stats publiques : `Cache-Control: s-maxage=30`
  - Config algorithme : DÃ©jÃ  cachÃ©e en mÃ©moire, mais pas partagÃ©e entre instances

### 7. Cache config algorithme non partagÃ©
- **Fichier :** `src/lib/algorithmConfig.ts`
- Utilise `globalThis.__algorithmConfigCache` pour cacher la config
- Chaque instance serverless Vercel a son propre cache
- Avec beaucoup de trafic â†’ chaque cold start = requÃªte DB supplÃ©mentaire
- **Solution :** Vercel KV ou Upstash Redis comme cache partagÃ©

---

## ğŸŸ¡ Points d'attention Ã  moyen terme

### 8. CoÃ»ts API IA (Gemini + OpenAI)
- Chaque utilisation de l'Oracle = 1 appel Gemini (ou OpenAI en fallback)
- Gemini Flash est peu coÃ»teux mais pas gratuit Ã  grande Ã©chelle
- 10K jugements/jour Ã— 30 jours = 300K appels/mois
- **Solution :** Cacher les rÃ©sultats pour les situations similaires (fuzzy matching)

### 9. Supabase limites
- Plan gratuit : 500Mo DB, 50K auth, 2Go bandwidth
- Plan Pro (~25â‚¬/mois) : 8Go DB, 100K auth, 250Go bandwidth
- Avec 10K utilisateurs/jour : ~5Go bandwidth/mois â†’ plan Pro nÃ©cessaire
- **Ã€ surveiller :** Taille de la table votes (croissance linÃ©aire avec l'usage)

### 10. Vercel limites
- Plan Hobby : 100Go bandwidth, serverless function timeout 10s
- Plan Pro (~20â‚¬/mois) : 1To bandwidth, timeout 60s
- La route Oracle utilise `maxDuration = 30` â†’ **nÃ©cessite le plan Pro**
- **Ã€ surveiller :** CoÃ»ts bandwidth si le site devient trÃ¨s populaire

---

## âœ… Ce qui est bien fait

| Ã‰lÃ©ment | DÃ©tail |
|---------|--------|
| Architecture stateless | Pas d'Ã©tat serveur â†’ scaling horizontal naturel |
| Compression activÃ©e | `compress: true` dans `next.config.ts` |
| Images optimisÃ©es | `formats: ['image/avif', 'image/webp']` |
| Cache long sur les statics | `immutable` sur manifest.json |
| AbortController | Annule les requÃªtes abandonÃ©es (changement de mode) |
| Dynamic imports | `canvas-confetti` et autres libs lourdes en lazy loading |
| Skeleton/Shimmer | Loading states pour Ã©viter les layout shifts |
| Error boundaries | Capture des erreurs sans crash global |

---

## ğŸ‘€ Analyse par persona

### ğŸ§‘â€ğŸ’¼ CEO
> - Si le jeu devient viral (objectif !), les coÃ»ts vont augmenter rapidement
> - **Budget infrastructure estimÃ© pour 10K utilisateurs/jour :**
>   - Vercel Pro : 20â‚¬/mois
>   - Supabase Pro : 25â‚¬/mois
>   - Upstash Redis : 10â‚¬/mois
>   - Gemini API : 20-50â‚¬/mois
>   - **Total : ~75-105â‚¬/mois**
> - Les race conditions ELO ne sont pas visibles par l'utilisateur mais dÃ©gradent la qualitÃ© des classements
> - **Le rate limiting cassÃ© est un risque business** (abus, scrapage, DDoS)

### ğŸ‘©â€ğŸ’» CTO
> - **Sprint 1 :** Upstash Redis pour le rate limiting (2-3h)
> - **Sprint 1 :** RequÃªtes atomiques pour les votes ELO (2h)
> - **Sprint 2 :** Pagination leaderboard (3h)
> - **Sprint 2 :** Vue SQL pour les participations (1h)
> - **Sprint 3 :** Cache Redis pour leaderboard et stats (3h)
> - **Sprint 3 :** Cache des rÃ©sultats Oracle similaires (1j)
> - Mettre en place des alertes de coÃ»ts sur Vercel et Supabase

### ğŸ“ˆ Growth Hacker
> - La scalabilitÃ© est invisible pour l'utilisateur SAUF quand Ã§a casse
> - Un site down pendant une campagne virale = argent brÃ»lÃ©
> - Les temps de rÃ©ponse API impactent l'engagement (chaque 100ms de latence = -1% engagement)
> - L'Oracle (Gemini) est le produit le plus "wow" â†’ il doit Ãªtre le plus fiable

---

## ğŸ“‹ Checklist scalabilitÃ© avant lancement

- [ ] Remplacer le rate limiting in-memory par Upstash Redis
- [ ] Corriger les race conditions ELO (requÃªtes atomiques SQL)
- [ ] Corriger les race conditions feedback (UPDATE incrÃ©mental)
- [ ] CrÃ©er une vue SQL pour les participations (remplacer le fetch de toutes les votes)
- [ ] Ajouter la pagination au leaderboard
- [ ] Ajouter des headers `Cache-Control` sur les endpoints publics
- [ ] Estimer les coÃ»ts mensuels pour 1K, 10K, 100K utilisateurs/jour
- [ ] Configurer des alertes de coÃ»ts sur Vercel, Supabase, GCP
- [ ] VÃ©rifier que le plan Vercel supporte `maxDuration=30` (Pro requis)
- [ ] ConsidÃ©rer un cache des rÃ©sultats Oracle pour rÃ©duire les appels IA
